<!DOCTYPE html>
<html>
<head>
    <title>üëø LLM Red Teaming Grounded Theory</title>
<style>
@font-face {
    font-family: hackerchaos;
    src: url("hackerchaos.otf") format("opentype");
}
@font-face {
    font-family: 'Classic Console Neue';
    src: url("clacon2.woff2") format("woff2");
}
@font-face {
    font-family: "OCR A Extended V2";
    src: url("ocrAextendedV2.woff")format("woff"),
}
body {
  background-image: url("summ1.jpg");
  background-repeat: no-repeat;
  background-attachment: fixed;
  background-size: cover;
  margin: 0;
  padding: 0;
  color: #ddd;
}
#content {
    margin: 0 10% 0 10%;
    background-color: rgba(0,0,0,0.5);
}   
h1, h2 {
    margin: 0 3%;
}
p, pre {
    font-family: 'Classic Console Neue';
    margin: 0 4%; 
    padding-top: 1em;
}
ul, ol {
    margin-left: 2em;
}
p,li{
    font-size: 1.3rem;
}
pre{
    font-size: 1.03rem;
}
li {
    font-family: 'Classic Console Neue';
}
h1 {
    font-family: hackerchaos;
    padding-top: 1.3em;
    padding-bottom: 1.9em;
    letter-spacing: 0.1em;
    font-size: 3.85rem;
    font-weight: normal;
}
h2 {
    padding-top: 2em; 
    font-family: "OCR A Extended V2", monospace;
    font-size: 2rem;
}
a {
    color: #f66;
}
.fixed {
    font-family:"OCR A Extended V2", monospace;
    margin-left: 4em;
}   
#footer {
    text-align: center;
    padding-top: 100px;
    padding-bottom: 100px;
    font-size: 3rem;
}   
p,li {
    line-height: 1.2;
}
pre,.fixed{
    color: #60DC98;
}
pre {margin-top: 1em}
</style>
</head>
<body>
<div id="content">
    <h1>Summon a demon and bind it.<br/> A grounded theory of LLM red teaming</h1>
    <h2>About</h2>
    <p>People attack large language models and they each do it differently. We interviewed dozens of experts to compile many hours of interviews about why and how people attack LLMs. This builds a "grounded theory" describing the activity and how it fits into the world. Questions we answer are:</p>
    <ul>
        <li>How is language model red teaming/adversarial prompt engineering/jailbreaking currently defined and practiced?</li>
        <li>How do people make sense of this activity? How do they describe it, how do they make sense of it, why do they do it?</li>
    </ul>
    <p>Our theory is based entirely on real, qualitative data from practitioners.</p>
    <p>We present results on:</p>
    <ol>
        <li>Strategies and techniques people use to attack LLMs</li>
        <li>Goals that LLM attackers have</li>
        <li>Model harms/failure modes attackers consider</li>
        <li>Metaphors used to understand attacking LLMs</li>
        <li>Connecting attacking LLMs to broader context</li>
    </ol>
    <p>Positions held by our contributing population:  analyst, artist, assistant professor, associate professor,
        computer programmer, distinguished engineer, game designer, head of developer experience, inventory at a weed farm, machine learning engineer, not working, penetration tester, phd student, policy
        research program manager, research manager, research scientist, senior principal research manager,
        senior research scientist, senior scientist, software developer, software engineer, software generalist,
        staff prompt engineer, startup founder, and student</p>
    <p>Institutions of partitipating include: Microsoft, Google, Robust Intelligence, Scale AI, a weed farm, Center for Human-Compatible AI,
        University College Dublin, University of Toronto, and the Hebrew University of Jerusalem</p>
    <h2>Strategies and techniques</h2>
    <p>Strategies: A grounded theory should include a description of strategies, activities that the participants perform in response to the core phenomenon. In military vernacular, strategy is <i>‚Äúthe art of
        winning a protracted struggle against adversaries [...] Power and control of the other‚Äôs behavior
        is the prize‚Äù</i> [38]. Strategy includes awareness of not only how to approach a task or goal, but also
        why and when. In our sample, approaches to the activity are rarely as systematic or as detailed as in
        the military understanding of a strategy, but can certainly be understood as the skillful application of
        stratagems: <i>‚Äúa plan, scheme, or trick for surprising or deceiving an enemy‚Äù</i>.</p>
    <p>Techniques are concrete approaches the red teamer may try while interacting with the
        language model. Several participants spoke of a toolbox at their disposition, but a few participants
        rejected this analogy with the argument that the utility of a tool is usually known, whereas the
        consequence of each interaction with a language models is not: <i>‚Äúit's less of a toolbox and just more
        like pile of powders and potions and what have you, and you've no idea what's in them‚Äù</i> (P19).</p>    
    <pre>
    Category      | Strategy          | Techniques
    ==============&#x256a;===================&#x256a;======================================
                  |                   | iPython 
                  |                   | Base64 
                  |                   | ROT13 
                  | Code & encode     | SQL 
                  |                   | Matrices 
                  |                   | Transformer translatable tokens 
                  |                   | Stop sequences 
                  &#x251c;-------------------&#x253c;--------------------------------------
    Language      |                   | Ignore previous instructions  
                  | Prompt injection  | Strong arm attack 
                  |                   | Stop sequences 
                  &#x251c;-------------------&#x253c;--------------------------------------
                  |                   | Formal language 
                  |                   | Servile language 
                  | Stylizing         | Synonymous language 
                  |                   | Capitalizing 
                  |                   | Give examples
    --------------&#x253c;-------------------&#x253c;--------------------------------------
                  | Persuasion &      | Distraction  
                  | manipulation      | Escalating 
                  |                   | Reverse psychology 
    Rhetoric      &#x251c;-------------------&#x253c;--------------------------------------
                  | Socratic          | Identity characteristics  
                  | questioning       | Social hierarchies 
    --------------&#x253c;-------------------&#x253c;--------------------------------------
    Possible      | Emulations        | Unreal computing
    worlds        &#x251c;-------------------&#x253c;--------------------------------------
                  | World building    | Opposite world  
                  |                   | Scenarios  
    --------------&#x253c;-------------------&#x253c;--------------------------------------
                  |                   | Poetry
                  | Switching genres  | Games  
                  |                   | Forum posts  
                  &#x251c;-------------------&#x253c;--------------------------------------
    Fictionalizing| Re-storying       | Goal hijacking
                  &#x251c;-------------------&#x253c;--------------------------------------
                  |                   | Claim authority  
                  | Roleplaying       | DAN (Do Anything Now)  
                  |                   | Personas  
    --------------&#x253c;-------------------&#x253c;--------------------------------------
                  |                   | Regenerate response 
                  | Scattershot       | Clean slate 
    Stratagems    |                   | Changing temperature  
                  &#x251c;-------------------&#x253c;--------------------------------------
                  | Meta-prompting    | Perspective-shifting 
                  |                   | Ask for examples     
    </pre>
    <h2>Metaphors in red teaming LLMs</h2>
    <p>In the interest of defining the core phenomenon, we tagged participants' uses of metaphors for their adversarial interactions with language models. This helps us understand how participants make sense of the model and their own role.</p>
    <p>The most frequently used metaphor is that of a <b>fortress</b>. The second most frequent metaphor is that of the model as an <b>object in space</b>, that can be pushed around and backed into a corner. These metaphors and, to some degree, the metaphor of the model as <b>material</b> share the characteristic of <i>exploring boundaries and limits</i> and potentially crossing them. The fortress-metaphor also reinforces the connection to red teaming, where the goal is to adopt an adversarial approach to find the (security) holes in some system.</p>
    <pre>
        Model metaphor          | Red teaming metaphor or example
        ========================&#x256a;=========================================================
                                | Bypassing safeguards
                                | Breaking a threshold   
                                | Bypassing the guard   
                                | Backdoors in the system   
        Model as fortress       | Boundary crossing   
                                | Explore its limit  
                                | Getting around the walls  
                                | Bypassing its net   
                                | The other side of the barrier
        ------------------------&#x253c;---------------------------------------------------------
                                | ``push it torwards your desired outcome''           
                                | Pushing the machine in a particular direction  
        Model as object         | Pushing it into a corner  
          in space              | ``one helps the model not back itself into a corner''  
                                | ``get it to fall over''   
        ------------------------&#x253c;---------------------------------------------------------
                                | Hijacking    
        Model as a vehicle      | Steering the model   
                                | Derail the model instructions
        ------------------------&#x253c;---------------------------------------------------------
                                | Gradient descent   
        Model as landscape      | ``(not) get stuck in the local maxima''   
                                | Boundary crossing  
        ------------------------&#x253c;---------------------------------------------------------
        Model as material       | ``let's try to bend it'' 
                                | ``let me try and break it''
        ------------------------&#x253c;---------------------------------------------------------
                                | ``they would use the kind of ideas and patterns from 
                                |    some religious services or whatever, and try to use 
        Model as deity          |    that as inspiration for messing around with these 
                                |    models''        
                                | ``Invoking GPT-3''
        ------------------------&#x253c;---------------------------------------------------------
                                | ``this ethics layer that they put on top of it, right?
        Model as cake           |    Not necessarily on top of it, but [that] they baked 
                                |    into it''
                                | ``Morality has been baked into this thing''  üç∞
        ------------------------&#x253c;---------------------------------------------------------
        Model as captive        | ``I'll force it to correct whatever it has done'' 
          /servant              | Subjugate these agents (anonymized) 
                                | It's difficult to get it to break out        
    </pre>
    <h2>Paper</h2>
    <p>Get the full story. Currently on arXiv. Read now <a href="https://arxiv.org/abs/2311.06237">arXiv:2311.06237</a></p>
    <h2>Data</h2>
    <p>&gt; Download the <a href="rtgt_highlights.tsv">quotes</a> used in the paper to form the theory</p>
    <p>&gt; Download <a href="code_structure.tsv">codes</a> established in construction of the theory</p>
    <h2>Media</h2>
    <p>Content featuring this research:</p>
    <p>&gt; <a href="https://www.docdroid.net/KfwKd1y/llm-redteaming-pdf">Structured LLM Red Teaming</a> - Allen Institute for AI, March 2023</p>
    <h2>Reference us</h2>
    <p>Cite our work as follows:</p>
    <p class="fixed">Inie, N., Stray, J., & Derczynski, L. (2024). Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming. PLoS One.</p>
    <p>In bibtex:</p>
    <p class="fixed">
        @article{demon,<br/>
        &nbsp;title={{Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming}},<br/>
        &nbsp;authors={Nanna Inie and Jonathan Stray and Leon Derczynski},<br/>
        &nbsp;journal={PLoS One},<br/>
        &nbsp;year=2024<br/>
        }
    </p>
    <h2>Find us:</h2>
    <p>Dr. <a href="https://nannainie.com">Nanna Inie</a>, ITU Copenhagen / University of Washington. <a href="https://x.com/nannainie">@nannainie</a></p>
    <p><a href="http://jonathanstray.com/">Jonathan Stray</a>, Berkeley Center for Human-Compatible AI. <a href="https://x.com/jonathanstray">@jonathanstray</a></p>
    <p>Prof. <a href="https://www.linkedin.com/in/leon-derczynski/">Leon Derczynski</a>, NVIDIA Corporation / ITU Copenhagen. <a href="https://x.com/leonderczynski">@leonderczynski</a></p>
    <h2>Credits</h2>
    <p>Named participants (random order): Dan Goldstein, Vinodkumar Prabhakaran, Hyrum Anderson, Lyra Cooley, Paul Nicholas, Murat
        Ayfer, Djam√© Seddah, Ian Ribeiro, Thomas Wood, Daniel Litt, Max Anton Brewer, Simon Willison,
        Sichu Lu, feddie xtzeth, Celeste Drummond, Sean Wang / swyx, Kai Greshake, Riley Goodside, Zvi
        Mowshowitz, Mathew Hardy, Marcin Junczys-Dowmunt, Harrison Chase, Brendan Dolan-Gavitt,
        Igor Brigadir, Lior Fox, Jonathan Stray. Heartfelt thanks to all named and not named. ü´∂</p>
    <p>Background image: <a href="https://sci-fi-london.com/">SCI-FI-LONDON</a> </p>
    <p>Fonts:  <a href="http://www.woodcutter.es/">hackerchaos</a>; </a><a href="https://webdraft.hu/fonts/classic-console/">Classic Console Neue</a>; <a href="https://www.onlinewebfonts.com/download/971c473a19b6bba1059ba6add6af78d7">OCR A Extended V2</a></p>
    <p>Words: the powers that be</p>
    <p id="footer">üòà</p>
</div>
</body>
</html>